{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3wF5wszaj97Y"
   },
   "source": [
    "# 以相似度为训练目标"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nnrWf3PCEzXL"
   },
   "source": [
    "## 生成训练数据，暂存于本地"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7aFIIQdwvPPM"
   },
   "outputs": [],
   "source": [
    "!git clone https://github.com/daibiaoxuwu/05wan3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fy2cDLkWvrvl"
   },
   "outputs": [],
   "source": [
    "!git clone https://github.com/daibiaoxuwu/05wan3b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gtgz-INDwsA2"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "path1 = '05wan3'\n",
    "path2 = '05wan3b/0'\n",
    "\n",
    "clocks = dict()\n",
    "x_train0 = []\n",
    "y_train0 = []\n",
    "for filename in os.listdir(path2):\n",
    "    if 'git' in filename: continue\n",
    "    #print(path1)\n",
    "    #ftimestr,number = path1.split('_')\n",
    "    clocks[int(filename.split('_')[0])]=int(filename.split('_')[1][:-4])\n",
    "    #clocks[int(ftimestr)]=int(number)\n",
    "keys = clocks.keys()\n",
    "for filename in os.listdir(path1):\n",
    "    if 'git' in filename or 'c.jpg' in filename: continue\n",
    "    ftime = int(filename.split('_')[0])\n",
    "    value = max(filter(lambda t:t<ftime,keys))\n",
    "    x_train0.append(cv2.imread(os.path.join(path1,filename), cv2.IMREAD_GRAYSCALE)/255.0)\n",
    "    y_train0.append(clocks[value])\n",
    "    \n",
    "print(len(x_train0),len(y_train0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "d0agG8K9wD3x"
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.countplot(y_train0)\n",
    "print(y_train0[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Nfh7yl-KKJQg"
   },
   "outputs": [],
   "source": [
    "\n",
    "from matplotlib import pyplot as plt\n",
    "lst = os.listdir(path1)\n",
    "for i in range(5):\n",
    "  plt.imshow(x_train0[i])\n",
    "  plt.show()\n",
    "  print(y_train0[i])\n",
    "  print(lst[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-lmz0keARk85"
   },
   "source": [
    "# 转为onehot，分离test和train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8vuxEAairfHZ"
   },
   "source": [
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VBl_86rWRk9F"
   },
   "source": [
    "# 装载Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0trJmd6DjqBZ"
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "# 安装 TensorFlow\n",
    "try:\n",
    "  # Colab only\n",
    "  %tensorflow_version 2.x\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8JqmdPzmRk9Q"
   },
   "source": [
    "# 输入数据生成器\n",
    "# 变为5张图片一叠"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "si3oM-1kaAZf"
   },
   "outputs": [],
   "source": [
    "idxes = []\n",
    "for i in range(10):idxes.append([])\n",
    "for idx, val in enumerate(y_train0):\n",
    "  idxes[val].append(idx)\n",
    "for i in range(10):\n",
    "  print(idxes[i][:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6GlHEnVJfA2D"
   },
   "source": [
    "# 搭建训练数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ASxEhVGMgMLD"
   },
   "source": [
    "## 搭建Overfit数据：只有十叠按序的照片"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-sH-e0ceeRol"
   },
   "outputs": [],
   "source": [
    "picnum = 5\n",
    "import random\n",
    "def train_generator():\n",
    "  while True:\n",
    "    dataout = []\n",
    "    for i in range(5):dataout.append([])\n",
    "    ansout = np.zeros((100,))\n",
    "    for train2 in range(100):\n",
    "      ans = random.randint(0,9)\n",
    "      idx2 = random.sample(idxes[ans],5)\n",
    "      for i in range(5):\n",
    "        dataout[i].append(x_train0[idx2[i]][:,:,np.newaxis])      \n",
    "      ansout[train2] = ans\n",
    "      #dataout.append(data)      \n",
    "    yield [np.stack(data2) for data2 in dataout],ansout \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wHLFpaRmfJwU"
   },
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.from_generator(train_generator,  (tf.float32, tf.float32), ([tf.TensorShape([5,12,12,1])]*5,tf.TensorShape([])))\n",
    "train_dataset = train_dataset.batch(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "y5AJdENrtgnG"
   },
   "outputs": [],
   "source": [
    "tx,ty = next(train_generator())\n",
    "print(tx[0].shape)\n",
    "print(ty.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VxjclcvUlLv8"
   },
   "source": [
    "\n",
    "# 搭建模型和训练\n",
    "现在的网络去掉dropout则可以拟合10张图片，\n",
    "但是加上dropout就拟合不了。\n",
    "从7张拟合5张的，则可以在两个epoch（每个epoch抽取60000次）内到80%。\n",
    "\n",
    "继续训练20张，一个epoch就到60%。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-nzds-gw75MO"
   },
   "outputs": [],
   "source": [
    "picnum = 5\n",
    "inputs = [tf.keras.layers.Input(shape=(12,12,1))  for i in range(picnum)]\n",
    "#inputs = tf.keras.layers.Input(shape=(5,12,12,1))\n",
    "\n",
    "conv_a1 = tf.keras.layers.Conv2D(32, (3, 3), padding = 'Same',  activation='relu')\n",
    "conva1 = [conv_a1(inputs[i]) for i in range(picnum)]\n",
    "conv_b1 = tf.keras.layers.Conv2D(32, (3, 3), padding = 'Same',  activation='relu')\n",
    "convb1 = [conv_b1(conva1[i]) for i in range(picnum)]\n",
    "\n",
    "conv_c1 = tf.keras.layers.Conv2D(32, (3, 3), padding = 'Same',  activation='relu')\n",
    "convc1 = [conv_c1(inputs[i]) for i in range(picnum)]\n",
    "conv_d1 = tf.keras.layers.Conv2D(32, (3, 3), padding = 'Same',  activation='relu')\n",
    "convd1 = [conv_d1(convc1[i]) for i in range(picnum)]\n",
    "\n",
    "convs1 = tf.stack(convb1)\n",
    "convf1 = [\n",
    "    tf.math.reduce_max(convs1, axis=[0]),\n",
    "    tf.math.reduce_mean(convs1, axis=[0]),\n",
    "    tf.math.reduce_min(convs1, axis=[0]),\n",
    "]\n",
    "\n",
    "conv_g1 = tf.keras.layers.Conv2D(32, (3, 3), padding = 'Same',  activation='relu')\n",
    "convg1 = [conv_g1(convf1[i]) for i in range(3)]\n",
    "\n",
    "convh1 = [tf.concat(convg1+[convd1[i]],axis=3) for i in range(picnum)]\n",
    "#------------------------------------------------------------------------------------------\n",
    "conv_a2 = tf.keras.layers.Conv2D(32, (3, 3), padding = 'Same',  activation='relu')\n",
    "conva2 = [conv_a2(convh1[i]) for i in range(picnum)]\n",
    "conv_b2 = tf.keras.layers.Conv2D(32, (3, 3), padding = 'Same',  activation='relu')\n",
    "convb2 = [conv_b2(conva2[i]) for i in range(picnum)]\n",
    "\n",
    "conv_c2 = tf.keras.layers.Conv2D(32, (3, 3), padding = 'Same',  activation='relu')\n",
    "convc2 = [conv_c2(inputs[i]) for i in range(picnum)]\n",
    "conv_d2 = tf.keras.layers.Conv2D(32, (3, 3), padding = 'Same',  activation='relu')\n",
    "convd2 = [conv_d2(convc2[i]) for i in range(picnum)]\n",
    "\n",
    "convs2 = tf.stack(convb2)\n",
    "convf2 = [\n",
    "    tf.math.reduce_max(convs2, axis=[0]),\n",
    "    tf.math.reduce_mean(convs2, axis=[0]),\n",
    "    tf.math.reduce_min(convs2, axis=[0]),\n",
    "]\n",
    "\n",
    "conv_g2 = tf.keras.layers.Conv2D(32, (3, 3), padding = 'Same',  activation='relu')\n",
    "convg2 = [conv_g2(convf2[i]) for i in range(3)]\n",
    "\n",
    "convh2 = [tf.concat(convg2+[convd2[i]],axis=3) for i in range(picnum)]\n",
    "#------------------------------------------------------------------------------------------\n",
    "conv_a3 = tf.keras.layers.Conv2D(32, (3, 3), padding = 'Same',  activation='relu')\n",
    "conva3 = [conv_a3(convh2[i]) for i in range(picnum)]\n",
    "conv_b3 = tf.keras.layers.Conv2D(32, (3, 3), padding = 'Same',  activation='relu')\n",
    "convb3 = [conv_b3(conva3[i]) for i in range(picnum)]\n",
    "\n",
    "conv_c3 = tf.keras.layers.Conv2D(32, (3, 3), padding = 'Same',  activation='relu')\n",
    "convc3 = [conv_c3(inputs[i]) for i in range(picnum)]\n",
    "conv_d3 = tf.keras.layers.Conv2D(32, (3, 3), padding = 'Same',  activation='relu')\n",
    "convd3 = [conv_d3(convc3[i]) for i in range(picnum)]\n",
    "\n",
    "convs3 = tf.stack(convb3)\n",
    "convf3 = [\n",
    "    tf.math.reduce_max(convs3, axis=[0]),\n",
    "    tf.math.reduce_mean(convs3, axis=[0]),\n",
    "    tf.math.reduce_min(convs3, axis=[0]),\n",
    "]\n",
    "\n",
    "conv_g3 = tf.keras.layers.Conv2D(32, (3, 3), padding = 'Same',  activation='relu')\n",
    "convg3 = [conv_g3(convf3[i]) for i in range(3)]\n",
    "\n",
    "convh3 = tf.concat(convg3+convd3,axis=3)\n",
    "\n",
    "convx1 = tf.keras.layers.Conv2D(32, (3, 3), padding = 'Same',  activation='relu')(convh3)\n",
    "convx2 = tf.keras.layers.Conv2D(32, (3, 3), padding = 'Same',  activation='relu')(convx1)\n",
    "convx3 = tf.keras.layers.Flatten()(convx2)\n",
    "convy1 = tf.keras.layers.Dense(128,activation='relu')(convx3)\n",
    "\n",
    "#keep_prob = tf.placeholder(tf.float32) # dropout (keep probability)\n",
    "\n",
    "#convy2 = tf.keras.layers.Dropout(1)(convy1)\n",
    "convy3 = tf.keras.layers.Dense(10)(convy1)\n",
    "\n",
    "model = tf.keras.Model(inputs=inputs, outputs=convy3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aiXxR3CUgs3P"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.summary()\n",
    "model.fit_generator(train_generator(),epochs=100,steps_per_epoch=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "c2ogrfi4gWds"
   },
   "source": [
    "# 去掉三个dropout时，一个epoch后达到99正确率。下面采用乱序的7张照片中取5张。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eMUYQrfCf6_u"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "def train_generator(slice):\n",
    "  for train in range(60000):\n",
    "    ans = random.randint(0,9)\n",
    "    idx2 = random.sample(idxes[ans][:slice],5)\n",
    "    data = np.stack([x_train0[ix] for ix in idx2],axis=2)\n",
    "    data = data[:,:,:,np.newaxis]\n",
    "    ansy = np.zeros(10)\n",
    "    ansy[ans] = 1\n",
    "    yield data,ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dzzTIoElf8xF"
   },
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.from_generator(train_generator,  (tf.float32, tf.float32), (tf.TensorShape([12,12,5,1]),tf.TensorShape([])), args=(7,))\n",
    "train_dataset = train_dataset.batch(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "m6o9FT6MeafV"
   },
   "outputs": [],
   "source": [
    "model.summary()\n",
    "model.fit(train_dataset,epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ix4mEL65on-w"
   },
   "source": [
    "# 训练并验证模型："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BEzw3u1LX9H_"
   },
   "outputs": [],
   "source": [
    "tx,ty = next(train_generator(5))\n",
    "for i in range(5):\n",
    "  plt.imshow(tx[:,:,i])\n",
    "  plt.show()\n",
    "print(ty)\n",
    "print(model.predict(np.array((tx,))))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "anaconda-cloud": {},
  "colab": {
   "collapsed_sections": [],
   "name": "trian4.ipynb",
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
