{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3wF5wszaj97Y"
   },
   "source": [
    "# 以相似度为训练目标"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XvbeBFq24MoG"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nnrWf3PCEzXL"
   },
   "source": [
    "## 训练数据生成器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ez32DOYVjHFU"
   },
   "outputs": [],
   "source": [
    "!git clone https://github.com/daibiaoxuwu/05wan8\n",
    "!git clone https://github.com/daibiaoxuwu/05wan8b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7aFIIQdwvPPM"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import random\n",
    "from matplotlib import pyplot as plt\n",
    "def read_data(path1,path2):\n",
    "\n",
    "  x_train0 = []\n",
    "  y_train0 = dict()\n",
    "  idxes = dict()\n",
    "\n",
    "  #read clock\n",
    "  #read and /255\n",
    "  for filename in os.listdir(path2):\n",
    "      if 'git' in filename: continue\n",
    "      y_train0[int(filename[:-4])]=cv2.imread(os.path.join(path2,filename), cv2.IMREAD_GRAYSCALE).astype('float32') /255.0      \n",
    "\n",
    "  keys = list(y_train0.keys())\n",
    "  \n",
    "  #read data\n",
    "  #add an axis and /255\n",
    "  \n",
    "  filelist = os.listdir(path1)\n",
    "  random.shuffle(filelist)\n",
    "  index = 0\n",
    "  for filename in filelist:\n",
    "      if 'git' in filename or 'c.jpg' in filename: continue\n",
    "      ftime = int(filename.split('_')[0])\n",
    "      value = max(filter(lambda t:t<ftime,keys))\n",
    "      if(abs(ftime-value)<10000):continue\n",
    "\n",
    "      x_train0.append(cv2.imread(os.path.join(path1,filename), cv2.IMREAD_GRAYSCALE).astype('float32')[:,:,np.newaxis]/255.0)\n",
    "      if value not in idxes:idxes[value]=[index]\n",
    "      else: idxes[value].append(index)\n",
    "      index += 1\n",
    "\n",
    "  #index data\n",
    "  print(len(x_train0),index,len(y_train0),len(idxes.keys()))\n",
    "  \n",
    "\n",
    "  #generator\n",
    "  def data_generator(ikeys_t):\n",
    "    while True:\n",
    "      dataout = []\n",
    "      for i in range(5):dataout.append([])\n",
    "      ansout = []\n",
    "      for train2 in range(100):\n",
    "        key = random.choice(ikeys_t)\n",
    "        idx2 = random.sample(idxes[key],5)\n",
    "        for i in range(5):\n",
    "          dataout[i].append(x_train0[idx2[i]])\n",
    "        ansout.append(y_train0[key])\n",
    "      yield [np.stack(data2) for data2 in dataout],np.stack(ansout)\n",
    "  \n",
    "  #split\n",
    "  ikeys = list(idxes.keys())\n",
    "  random.shuffle(ikeys)\n",
    "  ltrain = int(len(ikeys)*0.8)  \n",
    "  train_generator = data_generator(ikeys[:ltrain])\n",
    "  test_generator = data_generator(ikeys[ltrain:])\n",
    "\n",
    "  return train_generator,test_generator\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FfnEhjCTpreR"
   },
   "outputs": [],
   "source": [
    "train_generator,test_generator = read_data('05wan8','05wan8b')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-lmz0keARk85"
   },
   "source": [
    "# 数据初始化完成。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VBl_86rWRk9F"
   },
   "source": [
    "# 装载Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0trJmd6DjqBZ"
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "# 安装 TensorFlow\n",
    "try:\n",
    "  # Colab only\n",
    "  %tensorflow_version 2.x\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VxjclcvUlLv8"
   },
   "source": [
    "\n",
    "# 搭建模型和训练\n",
    "现在的网络去掉dropout则可以拟合10张图片，\n",
    "但是加上dropout就拟合不了。\n",
    "从7张拟合5张的，则可以在两个epoch（每个epoch抽取60000次）内到80%。\n",
    "\n",
    "继续训练20张，一个epoch就到60%。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-nzds-gw75MO"
   },
   "outputs": [],
   "source": [
    "picnum = 5\n",
    "inputs = [tf.keras.layers.Input(shape=(21,45,1))  for i in range(picnum)]\n",
    "#inputs = tf.keras.layers.Input(shape=(5,12,12,1))\n",
    "\n",
    "conv_a1 = tf.keras.layers.Conv2D(32, (3, 3), padding = 'Same',  activation='relu')\n",
    "conva1 = [conv_a1(inputs[i]) for i in range(picnum)]\n",
    "conv_b1 = tf.keras.layers.Conv2D(32, (3, 3), padding = 'Same',  activation='relu')\n",
    "convb1 = [conv_b1(conva1[i]) for i in range(picnum)]\n",
    "\n",
    "conv_c1 = tf.keras.layers.Conv2D(32, (3, 3), padding = 'Same',  activation='relu')\n",
    "convc1 = [conv_c1(inputs[i]) for i in range(picnum)]\n",
    "conv_d1 = tf.keras.layers.Conv2D(32, (3, 3), padding = 'Same',  activation='relu')\n",
    "convd1 = [conv_d1(convc1[i]) for i in range(picnum)]\n",
    "\n",
    "convs1 = tf.stack(convb1)\n",
    "convf1 = [\n",
    "    tf.math.reduce_max(convs1, axis=[0]),\n",
    "    tf.math.reduce_mean(convs1, axis=[0]),\n",
    "    tf.math.reduce_min(convs1, axis=[0]),\n",
    "]\n",
    "\n",
    "conv_g1 = tf.keras.layers.Conv2D(32, (3, 3), padding = 'Same',  activation='relu')\n",
    "convg1 = [conv_g1(convf1[i]) for i in range(3)]\n",
    "\n",
    "convh1 = [tf.concat(convg1+[convd1[i]],axis=3) for i in range(picnum)]\n",
    "#------------------------------------------------------------------------------------------\n",
    "conv_a2 = tf.keras.layers.Conv2D(32, (3, 3), padding = 'Same',  activation='relu')\n",
    "conva2 = [conv_a2(convh1[i]) for i in range(picnum)]\n",
    "conv_b2 = tf.keras.layers.Conv2D(32, (3, 3), padding = 'Same',  activation='relu')\n",
    "convb2 = [conv_b2(conva2[i]) for i in range(picnum)]\n",
    "\n",
    "conv_c2 = tf.keras.layers.Conv2D(32, (3, 3), padding = 'Same',  activation='relu')\n",
    "convc2 = [conv_c2(inputs[i]) for i in range(picnum)]\n",
    "conv_d2 = tf.keras.layers.Conv2D(32, (3, 3), padding = 'Same',  activation='relu')\n",
    "convd2 = [conv_d2(convc2[i]) for i in range(picnum)]\n",
    "\n",
    "convs2 = tf.stack(convb2)\n",
    "convf2 = [\n",
    "    tf.math.reduce_max(convs2, axis=[0]),\n",
    "    tf.math.reduce_mean(convs2, axis=[0]),\n",
    "    tf.math.reduce_min(convs2, axis=[0]),\n",
    "]\n",
    "\n",
    "conv_g2 = tf.keras.layers.Conv2D(32, (3, 3), padding = 'Same',  activation='relu')\n",
    "convg2 = [conv_g2(convf2[i]) for i in range(3)]\n",
    "\n",
    "convh2 = [tf.concat(convg2+[convd2[i]],axis=3) for i in range(picnum)]\n",
    "\n",
    "#------------------------------------------------------------------------------------------\n",
    "conv_a3 = tf.keras.layers.Conv2D(32, (3, 3), padding = 'Same',  activation='relu')\n",
    "conva3 = [conv_a3(convh2[i]) for i in range(picnum)]\n",
    "conv_b3 = tf.keras.layers.Conv2D(32, (3, 3), padding = 'Same',  activation='relu')\n",
    "convb3 = [conv_b3(conva3[i]) for i in range(picnum)]\n",
    "\n",
    "conv_c3 = tf.keras.layers.Conv2D(32, (3, 3), padding = 'Same',  activation='relu')\n",
    "convc3 = [conv_c3(inputs[i]) for i in range(picnum)]\n",
    "conv_d3 = tf.keras.layers.Conv2D(32, (3, 3), padding = 'Same',  activation='relu')\n",
    "convd3 = [conv_d3(convc3[i]) for i in range(picnum)]\n",
    "\n",
    "convs3 = tf.stack(convb3)\n",
    "convf3 = [\n",
    "    tf.math.reduce_max(convs3, axis=[0]),\n",
    "    tf.math.reduce_mean(convs3, axis=[0]),\n",
    "    tf.math.reduce_min(convs3, axis=[0]),\n",
    "]\n",
    "\n",
    "conv_g3 = tf.keras.layers.Conv2D(32, (3, 3), padding = 'Same',  activation='relu')\n",
    "convg3 = [conv_g3(convf3[i]) for i in range(3)]\n",
    "\n",
    "convh3 = tf.concat(convg3+convd3,axis=3)\n",
    "\n",
    "convx1 = tf.keras.layers.Conv2D(256, (3, 3), padding = 'Same',  activation='relu')(convh3)\n",
    "convx3 = tf.keras.layers.Conv2D(64, (3, 3), padding = 'Same', activation='relu')(convx1)\n",
    "'''\n",
    "convx3 = tf.keras.layers.Flatten()(convx2)\n",
    "\n",
    "#keep_prob = tf.placeholder(tf.float32) # dropout (keep probability)\n",
    "convx4 = tf.keras.layers.Dropout(0.2)(convx3)\n",
    "\n",
    "convy1 = tf.keras.layers.Dense(21*45)(convx4)\n",
    "#convy3 = tf.keras.layers.Dense(10,activation='softmax')(convy1)\n",
    "convy4 = tf.keras.layers.Reshape([21,45])(convy1)\n",
    "'''\n",
    "\n",
    "convx4 = tf.keras.layers.Conv2D(1, (1, 1), padding = 'Same',  activation='relu')(convx3)\n",
    "\n",
    "model = tf.keras.Model(inputs=inputs, outputs=convx4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aiXxR3CUgs3P"
   },
   "outputs": [],
   "source": [
    "#tf.reduce_mean(tf.image.ssim(reconstructed, truth, 1.0))\n",
    "model.compile(optimizer='adam',#tf.keras.optimizers.Adam(lr=0.01, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0),\n",
    "                #loss=lambda y_pred,y_true:1-tf.reduce_mean(tf.image.ssim_multiscale(tf.clip_by_value(y_pred,0,1), y_true, 255))#-tf.reduce_mean(tf.image.psnr(tf.clip_by_value(y_pred,0,1), y_true, 1.0))\n",
    "              loss='mse',\n",
    "              metrics=['mse']\n",
    "              )\n",
    "            \n",
    "#model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qMByUd_CZrg8"
   },
   "source": [
    "# 开始训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9qeXrdtDT41r"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "import math\n",
    "#reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', patience=5, mode='auto')\n",
    "def step_decay(epoch):\n",
    "  initial_lrate = 0.001\n",
    "  drop = 0.5\n",
    "  epochs_drop = 10.0\n",
    "  lrate = initial_lrate * math.pow(drop, math.floor((1+epoch)/epochs_drop))\n",
    "  return lrate\n",
    "  \n",
    "reduce_lr = tf.keras.callbacks.LearningRateScheduler(step_decay)\n",
    "'''\n",
    "#model.load_weights('/content/drive/My Drive/checkpoints/checkpoints/my_checkpoint')\n",
    "#os.mkdir('/content/drive/My Drive/checkpoints')\n",
    "checkpoint_path = \"/content/drive/My Drive/checkpoints/training_1/cp.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "os.mkdir(checkpoint_dir)\n",
    "#model.load_weights(checkpoint_path)\n",
    "# Create checkpoint callback\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(checkpoint_path, \n",
    "                                                 save_weights_only=False,\n",
    "                                                 verbose=0)\n",
    "\n",
    "\n",
    "model.fit_generator(train_generator,epochs=200,steps_per_epoch=2000,validation_data=test_generator,validation_steps=50,validation_freq=1,callbacks=[cp_callback])#,callbacks=[reduce_lr])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2FDL6IYRQtz9"
   },
   "source": [
    "# 测试正确率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CAhBlSEAhnFq"
   },
   "outputs": [],
   "source": [
    "data,ans = next(test_generator)\n",
    "data = [data[x][5][np.newaxis,:,:,:] for x in range(5)]\n",
    "ans = ans[5]\n",
    "import matplotlib\n",
    "cmap = matplotlib.cm.gray \n",
    "cmap.set_bad(color='black')\n",
    "\n",
    "pred = model.predict(data)\n",
    "pred[0,0,0,0]=0\n",
    "ans[0,0]=0\n",
    "for i in range(5):\n",
    "  plt.subplot(321+i)\n",
    "  plt.imshow(data[i][0,:,:,0],cmap=cmap)\n",
    "plt.show()\n",
    "plt.imshow(np.clip(pred[0,:,:,0],0,1),cmap=cmap)\n",
    "print(pred[0,0,0])\n",
    "\n",
    "plt.show()\n",
    "plt.imshow(pred[0,:,:,0],cmap=cmap)\n",
    "plt.show()\n",
    "plt.imshow(ans,cmap=cmap)\n",
    "plt.show()\n",
    "from skimage.metrics import peak_signal_noise_ratio,structural_similarity, mean_squared_error\n",
    "print(peak_signal_noise_ratio(np.clip(pred[0,:,:,0],0,1),ans))\n",
    "print(structural_similarity(np.clip(pred[0,:,:,0],0,1),ans))\n",
    "print(mean_squared_error(np.clip(pred[0,:,:,0],0,1),ans))\n",
    "pic = np.ones(ans.shape)\n",
    "print(mean_squared_error(np.clip(pic,0,1),ans))\n",
    "#ssims = tf.image.ssim(tf.clip_by_value(pred[0],0,1), ans, 1.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bySeLn4Z-pHx"
   },
   "outputs": [],
   "source": [
    "from skimage.metrics import mean_squared_error as mse\n",
    "from skimage.metrics import peak_signal_noise_ratio,structural_similarity, mean_squared_error\n",
    "\n",
    "bigdiff = 0\n",
    "bigdata = 0\n",
    "bigans = 0\n",
    "bigpred = 0\n",
    "for it in range(1):\n",
    "  data,ans = next(train_generator)\n",
    "  pred = model.predict(data)\n",
    "  for it2 in range(100):\n",
    "    data2 = [data[x][it2][np.newaxis,:,:,:] for x in range(5)]\n",
    "    ans2 = ans[it2]\n",
    "    \n",
    "    diff = structural_similarity(np.clip(pred[it2,:,:,0],0,1),ans2)\n",
    "    if(diff > bigdiff):\n",
    "      bigdiff=diff\n",
    "      bigdata=data2\n",
    "      bigans=ans2\n",
    "      bigpred=pred[it2,:,:,0]\n",
    "\n",
    "\n",
    "for i in range(5):\n",
    "  plt.subplot(321+i)\n",
    "  plt.imshow(bigdata[i][0,:,:,0],cmap='gray')\n",
    "plt.show()\n",
    "plt.imshow(bigpred,cmap='gray')\n",
    "plt.show()\n",
    "plt.imshow(bigans,cmap='gray')\n",
    "plt.show()\n",
    "print(bigdiff)\n",
    "print(mean_squared_error(np.clip(bigpred,0,1),bigans))\n",
    "\n",
    "\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "b6fXbUXf7E9c"
   },
   "outputs": [],
   "source": [
    "from skimage.metrics import mean_squared_error as mse\n",
    "from skimage.metrics import peak_signal_noise_ratio,structural_similarity\n",
    "\n",
    "bigdiff = 0\n",
    "bigdata = 0\n",
    "bigans = 0\n",
    "bigpred = 0\n",
    "diffs=[]\n",
    "for it in range(100):\n",
    "  data,ans = next(train_generator)\n",
    "  pred = model2.predict(data)\n",
    "  diffs2 = []\n",
    "  for it2 in range(100):\n",
    "    data2 = [data[x][it2][np.newaxis,:,:,:] for x in range(5)]\n",
    "    ans2 = ans[it2]\n",
    "     #   print(ans2.dtype)\n",
    "    #print(pred.dtype)\n",
    "#    print(ans2.max(),ans2.min())\n",
    "#    print(pred[it2,:,:,0].max(),pred[it2,:,:,0].min())\n",
    "    diff = structural_similarity(np.clip(pred[it2,:,:,0],0,1),ans2)\n",
    "    diffs2.append(diff)\n",
    "  diffs.append(np.average(diffs2))\n",
    "plt.hist(diffs)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "anaconda-cloud": {},
  "colab": {
   "collapsed_sections": [],
   "name": "train6.ipynb",
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
