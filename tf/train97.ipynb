{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "anaconda-cloud": {},
    "colab": {
      "name": "train8.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.2"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "3wF5wszaj97Y"
      },
      "source": [
        "# 以相似度为训练目标"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XvbeBFq24MoG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "nnrWf3PCEzXL"
      },
      "source": [
        "## 训练数据生成器"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ez32DOYVjHFU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git clone https://github.com/daibiaoxuwu/05wan11\n",
        "!git clone https://github.com/daibiaoxuwu/05wan11b\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7aFIIQdwvPPM",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import random\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "datasizex = 11\n",
        "datasizey = 11\n",
        "picsizex = 18\n",
        "picsizey = 41\n",
        "picnum = 30\n",
        "lowpercent = 125.0\n",
        "highpercent = 233.0\n",
        "\n",
        "def read_data(path1,path2):\n",
        "\n",
        "  x_train0 = []\n",
        "  y_train0 = dict()\n",
        "  idxes = dict()\n",
        "\n",
        "  #read clock\n",
        "  #read and /255\n",
        "  for filename in os.listdir(path2):\n",
        "      if 'git' in filename: continue\n",
        "      ans = cv2.imread(os.path.join(path2,filename),cv2.IMREAD_GRAYSCALE).astype('float32')     \n",
        "      ans = np.clip((ans-lowpercent)/(highpercent - lowpercent),0,1)\n",
        "      y_train0[int(filename[:-4])]=ans\n",
        "\n",
        "  keys = list(y_train0.keys())\n",
        "  \n",
        "  #read data\n",
        "  #add an axis and /255\n",
        "  \n",
        "  filelist = os.listdir(path1)\n",
        "  random.shuffle(filelist)\n",
        "  index = 0\n",
        "  for filename in filelist:\n",
        "      if 'git' in filename or 'c.jpg' in filename: continue\n",
        "      ftime = int(filename.split('_')[0])\n",
        "      value = max(filter(lambda t:t<ftime,keys))\n",
        "      if(abs(ftime-value)<10000):continue\n",
        "\n",
        "      x_train0.append(cv2.imread(os.path.join(path1,filename)).astype('float32')/255.0)\n",
        "      if value not in idxes:idxes[value]=[index]\n",
        "      else: idxes[value].append(index)\n",
        "      index += 1\n",
        "\n",
        "  #index data\n",
        "  print(len(x_train0),index,len(y_train0),len(idxes.keys()))\n",
        "  lens = [len(i) for i in idxes.values()]\n",
        "  print(min(lens),max(lens),np.average(lens))\n",
        "  for key,val in list(idxes.items()):\n",
        "    if len(val)<picnum:\n",
        "      idxes.pop(key)\n",
        "  \n",
        "\n",
        "  #generator\n",
        "  def data_generator(ikeys_t):\n",
        "    while True:\n",
        "      dataout = []\n",
        "      for i in range(picnum):dataout.append([])\n",
        "      ansout = []\n",
        "      for train2 in range(100):\n",
        "        '''\n",
        "        while True:\n",
        "          key = random.choice(ikeys_t)\n",
        "          idx2 = random.sample(idxes[key],picnum)\n",
        "          posx = random.randint(0,picsizex-datasizex)\n",
        "          posy = random.randint(0,picsizey-datasizey)\n",
        "          pic = x_train0[idx2[i]][posx:posx+datasizex,posy:posy+datasizey,:]\n",
        "          if(np.sum(pic) < 175):\n",
        "            for i in range(picnum):\n",
        "              dataout[i].append(x_train0[idx2[i]][posx:posx+datasizex,posy:posy+datasizey,:])\n",
        "            ansout.append(y_train0[key][posx:posx+datasizex,posy:posy+datasizey])\n",
        "            break\n",
        "        '''\n",
        "        key = random.choice(ikeys_t)\n",
        "        idx2 = random.sample(idxes[key],picnum)\n",
        "        posx = random.randint(0,picsizex-datasizex)\n",
        "        posy = random.randint(0,picsizey-datasizey)\n",
        "        pic = x_train0[idx2[i]][posx:posx+datasizex,posy:posy+datasizey,:]\n",
        "        for i in range(picnum):\n",
        "          dataout[i].append(x_train0[idx2[i]][posx:posx+datasizex,posy:posy+datasizey,:])\n",
        "        ansout.append(y_train0[key][posx:posx+datasizex,posy:posy+datasizey])\n",
        "      yield [np.stack(data2) for data2 in dataout],np.stack(ansout)\n",
        "  def pic_generator(ikeys_t):\n",
        "    while True:\n",
        "      key = random.choice(ikeys_t)\n",
        "      idx2 = random.sample(idxes[key],picnum)\n",
        "      data=[x_train0[i] for i in idx2]\n",
        "      ans=y_train0[key]\n",
        "      yield data,ans\n",
        "\n",
        "  #split\n",
        "  ikeys = list(idxes.keys())\n",
        "  random.shuffle(ikeys)\n",
        "  ltrain = int(len(ikeys)*0.8)  \n",
        "  train_generator = data_generator(ikeys[:ltrain])\n",
        "  test_generator = data_generator(ikeys[ltrain:])\n",
        "  train_pic_generator = pic_generator(ikeys[:ltrain])\n",
        "  test_pic_generator = pic_generator(ikeys[ltrain:])\n",
        "\n",
        "  return train_generator,test_generator,train_pic_generator,test_pic_generator\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FfnEhjCTpreR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "from matplotlib import pyplot as plt\n",
        "train_generator,test_generator,train_pic_generator,test_pic_generator = read_data('05wan11','05wan11b')\n",
        "data,ans = next(train_generator)\n",
        "for pics in data:\n",
        "  for i in range(6):\n",
        "    plt.subplot(231+i)\n",
        "    plt.imshow(pics[i,:,:,0],cmap='gray')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "16T8NTH7IsZH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ans[0,0,0]=0\n",
        "ans[0,1,0]=1\n",
        "plt.imshow(ans[0],cmap='gray')\n",
        "print(np.sum(ans[0]))\n",
        "print(np.min(ans[0]),np.max(ans[0]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "-lmz0keARk85"
      },
      "source": [
        "# 数据初始化完成。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "VBl_86rWRk9F"
      },
      "source": [
        "# 装载Tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0trJmd6DjqBZ",
        "colab": {}
      },
      "source": [
        "\n",
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "# 安装 TensorFlow\n",
        "try:\n",
        "  # Colab only\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "    pass\n",
        "\n",
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "VxjclcvUlLv8"
      },
      "source": [
        "\n",
        "# 搭建模型和训练\n",
        "现在的网络去掉dropout则可以拟合10张图片，\n",
        "但是加上dropout就拟合不了。\n",
        "从7张拟合5张的，则可以在两个epoch（每个epoch抽取60000次）内到80%。\n",
        "\n",
        "继续训练20张，一个epoch就到60%。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-nzds-gw75MO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "inputs = [tf.keras.layers.Input(shape=(datasizex,datasizey,3))  for i in range(picnum)]\n",
        "#inputs = tf.keras.layers.Input(shape=(5,12,12,1))\n",
        "\n",
        "conv_a1 = tf.keras.layers.Conv2D(32, (3, 3), padding = 'Same',  activation='relu')\n",
        "conva1 = [conv_a1(inputs[i]) for i in range(picnum)]\n",
        "conv_b1 = tf.keras.layers.Conv2D(32, (3, 3), padding = 'Same',  activation='relu')\n",
        "convb1 = [conv_b1(conva1[i]) for i in range(picnum)]\n",
        "\n",
        "conv_c1 = tf.keras.layers.Conv2D(32, (3, 3), padding = 'Same',  activation='relu')\n",
        "convc1 = [conv_c1(inputs[i]) for i in range(picnum)]\n",
        "conv_d1 = tf.keras.layers.Conv2D(32, (3, 3), padding = 'Same',  activation='relu')\n",
        "convd1 = [conv_d1(convc1[i]) for i in range(picnum)]\n",
        "\n",
        "convs1 = tf.stack(convb1)\n",
        "convf1 = [\n",
        "    tf.math.reduce_max(convs1, axis=[0]),\n",
        "    tf.math.reduce_mean(convs1, axis=[0]),\n",
        "    tf.math.reduce_min(convs1, axis=[0]),\n",
        "]\n",
        "\n",
        "conv_g1 = tf.keras.layers.Conv2D(32, (3, 3), padding = 'Same',  activation='relu')\n",
        "convg1 = [conv_g1(convf1[i]) for i in range(3)]\n",
        "\n",
        "convh1 = [tf.concat(convg1+[convd1[i]],axis=3) for i in range(picnum)]\n",
        "#------------------------------------------------------------------------------------------\n",
        "conv_a2 = tf.keras.layers.Conv2D(32, (3, 3), padding = 'Same',  activation='relu')\n",
        "conva2 = [conv_a2(convh1[i]) for i in range(picnum)]\n",
        "conv_b2 = tf.keras.layers.Conv2D(32, (3, 3), padding = 'Same',  activation='relu')\n",
        "convb2 = [conv_b2(conva2[i]) for i in range(picnum)]\n",
        "\n",
        "conv_c2 = tf.keras.layers.Conv2D(32, (3, 3), padding = 'Same',  activation='relu')\n",
        "convc2 = [conv_c2(inputs[i]) for i in range(picnum)]\n",
        "conv_d2 = tf.keras.layers.Conv2D(32, (3, 3), padding = 'Same',  activation='relu')\n",
        "convd2 = [conv_d2(convc2[i]) for i in range(picnum)]\n",
        "\n",
        "convs2 = tf.stack(convb2)\n",
        "convf2 = [\n",
        "    tf.math.reduce_max(convs2, axis=[0]),\n",
        "    tf.math.reduce_mean(convs2, axis=[0]),\n",
        "    tf.math.reduce_min(convs2, axis=[0]),\n",
        "]\n",
        "\n",
        "conv_g2 = tf.keras.layers.Conv2D(32, (3, 3), padding = 'Same',  activation='relu')\n",
        "convg2 = [conv_g2(convf2[i]) for i in range(3)]\n",
        "\n",
        "convh2 = [tf.concat(convg2+[convd2[i]],axis=3) for i in range(picnum)]\n",
        "\n",
        "#------------------------------------------------------------------------------------------\n",
        "conv_a3 = tf.keras.layers.Conv2D(32, (3, 3), padding = 'Same',  activation='relu')\n",
        "conva3 = [conv_a3(convh2[i]) for i in range(picnum)]\n",
        "conv_b3 = tf.keras.layers.Conv2D(32, (3, 3), padding = 'Same',  activation='relu')\n",
        "convb3 = [conv_b3(conva3[i]) for i in range(picnum)]\n",
        "\n",
        "conv_c3 = tf.keras.layers.Conv2D(32, (3, 3), padding = 'Same',  activation='relu')\n",
        "convc3 = [conv_c3(inputs[i]) for i in range(picnum)]\n",
        "conv_d3 = tf.keras.layers.Conv2D(32, (3, 3), padding = 'Same',  activation='relu')\n",
        "convd3 = [conv_d3(convc3[i]) for i in range(picnum)]\n",
        "\n",
        "convs3 = tf.stack(convb3)\n",
        "convf3 = [\n",
        "    tf.math.reduce_max(convs3, axis=[0]),\n",
        "    tf.math.reduce_mean(convs3, axis=[0]),\n",
        "    tf.math.reduce_min(convs3, axis=[0]),\n",
        "]\n",
        "\n",
        "conv_g3 = tf.keras.layers.Conv2D(32, (3, 3), padding = 'Same',  activation='relu')\n",
        "convg3 = [conv_g3(convf3[i]) for i in range(3)]\n",
        "\n",
        "convh3 = tf.concat(convg3+convd3,axis=3)\n",
        "\n",
        "convx1 = tf.keras.layers.Conv2D(256, (3, 3), padding = 'Same',  activation='relu')(convh3)\n",
        "convx3 = tf.keras.layers.Conv2D(64, (3, 3), padding = 'Same', activation='relu')(convx1)\n",
        "'''\n",
        "convx3 = tf.keras.layers.Flatten()(convx2)\n",
        "\n",
        "#keep_prob = tf.placeholder(tf.float32) # dropout (keep probability)\n",
        "convx4 = tf.keras.layers.Dropout(0.2)(convx3)\n",
        "\n",
        "convy1 = tf.keras.layers.Dense(21*45)(convx4)\n",
        "#convy3 = tf.keras.layers.Dense(10,activation='softmax')(convy1)\n",
        "convy4 = tf.keras.layers.Reshape([21,45])(convy1)\n",
        "'''\n",
        "\n",
        "convx4 = tf.keras.layers.Conv2D(1, (3, 3), padding = 'Same')(convx3)\n",
        "\n",
        "model = tf.keras.Model(inputs=inputs, outputs=convx4)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "aiXxR3CUgs3P",
        "colab": {}
      },
      "source": [
        "#tf.reduce_mean(tf.image.ssim(reconstructed, truth, 1.0))\n",
        "model.compile(optimizer='adam',#tf.keras.optimizers.Adam(lr=0.01, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0),\n",
        "                #loss=lambda y_pred,y_true:1-tf.reduce_mean(tf.image.ssim_multiscale(tf.clip_by_value(y_pred,0,1), y_true, 255))#-tf.reduce_mean(tf.image.psnr(tf.clip_by_value(y_pred,0,1), y_true, 1.0))\n",
        "              loss='mse',\n",
        "              metrics=['mse']\n",
        "              )\n",
        "            \n",
        "#model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qMByUd_CZrg8",
        "colab_type": "text"
      },
      "source": [
        "# 开始训练"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9qeXrdtDT41r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Suppress some level of logs\n",
        "import logging\n",
        "logging.getLogger(\"tensorflow\").setLevel(logging.WARN)\n",
        "checkpoint_path = \"/content/drive/My Drive/checkpoints/training_13/cp.ckpt\"\n",
        "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
        "if os.path.exists(checkpoint_dir):\n",
        "  model.load_weights(checkpoint_path)\n",
        "\n",
        "cp_callback = tf.keras.callbacks.ModelCheckpoint(checkpoint_path,save_weights_only=True)\n",
        "model.fit_generator(train_generator,epochs=200,steps_per_epoch=500,validation_data=test_generator,validation_steps=50,validation_freq=1,verbose=2,callbacks=[cp_callback])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2FDL6IYRQtz9",
        "colab_type": "text"
      },
      "source": [
        "# 测试正确率"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IUmXvr4a9Vl1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def softmax(x):\n",
        "    exp_x = np.exp(x)\n",
        "    softmax_x = exp_x / np.sum(exp_x)\n",
        "    return softmax_x \n",
        "\n",
        "data,ans = next(test_generator)\n",
        "data = [data[x][5][np.newaxis,:,:,:] for x in range(picnum)]\n",
        "ans = ans[5]\n",
        "import matplotlib\n",
        "cmap = matplotlib.cm.gray \n",
        "cmap.set_bad(color='black')\n",
        "\n",
        "pred = model.predict(data) #shape:(1,11,11,1) because last layer is conv not dense\n",
        "#pred = np.clip(pred,0,1)\n",
        "#pred = (pred-np.min(pred))/(np.max(pred)-np.min(pred))\n",
        "#pred = softmax(pred)\n",
        "pred[0,0,0,0]=0\n",
        "pred[0,0,1,0]=1\n",
        "print(np.sum(ans),np.min(ans),np.max(ans))\n",
        "ans[0,0]=0\n",
        "ans[0,1]=1\n",
        "for i in range(5):\n",
        "  plt.subplot(321+i)\n",
        "  plt.imshow(data[i][0,:,:,0],cmap=cmap)\n",
        "plt.colorbar()\n",
        "plt.show()\n",
        "plt.imshow(pred[0,:,:,0],cmap=cmap)\n",
        "plt.colorbar()\n",
        "plt.show()\n",
        "#ans = np.clip((ans-np.percentile(ans,10))/(np.percentile(ans,90)-np.percentile(ans,10)),0,1)\n",
        "plt.imshow(ans,cmap=cmap)\n",
        "plt.colorbar()\n",
        "plt.show()\n",
        "from skimage.metrics import peak_signal_noise_ratio,structural_similarity, mean_squared_error\n",
        "print(peak_signal_noise_ratio(np.clip(pred[0,:,:,0],0,1),ans))\n",
        "print(structural_similarity(np.clip(pred[0,:,:,0],0,1),ans))\n",
        "print(mean_squared_error(np.clip(pred[0,:,:,0],0,1),ans))\n",
        "pic = np.ones(ans.shape)\n",
        "print(mean_squared_error(np.clip(pic*5-4,0,1),ans))\n",
        "\n",
        "#ssims = tf.image.ssim(tf.clip_by_value(pred[0],0,1), ans, 1.0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lu61jCnJ0fQ2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict_pic(xpics,model):\n",
        "  # xpic: array of 5 with size(22,52,1)\n",
        "  picout = np.zeros((picsizex,picsizey),dtype=np.float32)\n",
        "  piclayer = np.zeros((picsizex,picsizey),dtype=int)\n",
        "  for posx in range(0,picsizex+1-datasizex):\n",
        "    for posy in range(0,picsizey+1-datasizey):\n",
        "      dataout = [pic[np.newaxis,posx:posx+datasizex,posy:posy+datasizey,:] for pic in xpics]\n",
        "      pred = model.predict(dataout)\n",
        "      picout[posx:posx+datasizex,posy:posy+datasizey] += pred[0,:,:,0]\n",
        "      piclayer[posx:posx+datasizex,posy:posy+datasizey] += np.ones((datasizex,datasizey),dtype=int)\n",
        "  picout /= piclayer\n",
        "  return picout\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CAhBlSEAhnFq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data,ans = next(test_pic_generator)\n",
        "\n",
        "import matplotlib\n",
        "cmap = matplotlib.cm.gray \n",
        "cmap.set_bad(color='black')\n",
        "\n",
        "pred = predict_pic(data,model)\n",
        "\n",
        "for i in range(6):\n",
        "  plt.subplot(231+i)\n",
        "  plt.imshow(data[i])\n",
        "\n",
        "plt.show()\n",
        "pred[0,0]=0\n",
        "pred[0,1]=1\n",
        "plt.imshow(pred,cmap=cmap)\n",
        "plt.colorbar()\n",
        "plt.show()\n",
        "ans[0,0]=0\n",
        "ans[0,1]=1\n",
        "plt.imshow(ans,cmap=cmap)\n",
        "plt.colorbar()\n",
        "plt.show()\n",
        "from skimage.metrics import peak_signal_noise_ratio,structural_similarity, mean_squared_error\n",
        "print(peak_signal_noise_ratio(np.clip(pred,0,1),ans))\n",
        "print(structural_similarity(np.clip(pred,0,1),ans))\n",
        "print(mean_squared_error(np.clip(pred,0,1),ans))\n",
        "pic = np.ones(ans.shape)*0.9\n",
        "print(mean_squared_error(np.clip(pic,0,1),ans))\n",
        "#ssims = tf.image.ssim(tf.clip_by_value(pred,0,1), ans, 1.0)\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}