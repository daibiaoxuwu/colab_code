{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "sess = tf.Session()\n",
    "\n",
    "from keras import backend as K\n",
    "K.set_session(sess)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this placeholder will contain our input digits, as flat vectors\n",
    "img = tf.placeholder(tf.float32, shape=(None, 784))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense\n",
    "\n",
    "# Keras layers can be called on TensorFlow tensors:\n",
    "x = Dense(128, activation='relu')(img)  # fully-connected layer with 128 units and ReLU activation\n",
    "x = Dense(128, activation='relu')(x)\n",
    "preds = Dense(10, activation='softmax')(x)  # output layer with 10 units and a softmax activation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = tf.placeholder(tf.float32, shape=(None, 10))\n",
    "\n",
    "from keras.objectives import categorical_crossentropy\n",
    "loss = tf.reduce_mean(categorical_crossentropy(labels, preds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist_data = input_data.read_data_sets('MNIST_data', one_hot=True)\n",
    "\n",
    "train_step = tf.train.GradientDescentOptimizer(0.5).minimize(loss)\n",
    "\n",
    "# Initialize all variables\n",
    "init_op = tf.global_variables_initializer()\n",
    "sess.run(init_op)\n",
    "\n",
    "# Run training loop\n",
    "with sess.as_default():\n",
    "    for i in range(100):\n",
    "        batch = mnist_data.train.next_batch(50)\n",
    "        train_step.run(feed_dict={img: batch[0],\n",
    "                                  labels: batch[1]})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.metrics import categorical_accuracy as accuracy\n",
    "\n",
    "acc_value = accuracy(labels, preds)\n",
    "with sess.as_default():\n",
    "    print acc_value.eval(feed_dict={img: mnist_data.test.images,\n",
    "                                    labels: mnist_data.test.labels})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "print K.learning_phase()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train mode\n",
    "train_step.run(feed_dict={x: batch[0], labels: batch[1], K.learning_phase(): 1})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dropout\n",
    "from keras import backend as K\n",
    "\n",
    "img = tf.placeholder(tf.float32, shape=(None, 784))\n",
    "labels = tf.placeholder(tf.float32, shape=(None, 10))\n",
    "\n",
    "x = Dense(128, activation='relu')(img)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "preds = Dense(10, activation='softmax')(x)\n",
    "\n",
    "loss = tf.reduce_mean(categorical_crossentropy(labels, preds))\n",
    "\n",
    "train_step = tf.train.GradientDescentOptimizer(0.5).minimize(loss)\n",
    "with sess.as_default():\n",
    "    for i in range(100):\n",
    "        batch = mnist_data.train.next_batch(50)\n",
    "        train_step.run(feed_dict={img: batch[0],\n",
    "                                  labels: batch[1],\n",
    "                                  K.learning_phase(): 1})\n",
    "\n",
    "acc_value = accuracy(labels, preds)\n",
    "with sess.as_default():\n",
    "    print acc_value.eval(feed_dict={img: mnist_data.test.images,\n",
    "                                    labels: mnist_data.test.labels,\n",
    "                                    K.learning_phase(): 0})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, shape=(None, 20, 64))\n",
    "with tf.name_scope('block1'):\n",
    "    y = LSTM(32, name='mylstm')(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('/gpu:0'):\n",
    "    x = tf.placeholder(tf.float32, shape=(None, 20, 64))\n",
    "    y = LSTM(32)(x)  # all ops / variables in the LSTM layer will live on GPU:0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import LSTM\n",
    "import tensorflow as tf\n",
    "\n",
    "my_graph = tf.Graph()\n",
    "with my_graph.as_default():\n",
    "    x = tf.placeholder(tf.float32, shape=(None, 20, 64))\n",
    "    y = LSTM(32)(x)  # all ops / variables in the LSTM layer are created as part of our graph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate a Keras layer\n",
    "lstm = LSTM(32)\n",
    "\n",
    "# instantiate two TF placeholders\n",
    "x = tf.placeholder(tf.float32, shape=(None, 20, 64))\n",
    "y = tf.placeholder(tf.float32, shape=(None, 20, 64))\n",
    "\n",
    "# encode the two tensors with the *same* LSTM weights\n",
    "x_encoded = lstm(x)\n",
    "y_encoded = lstm(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import BatchNormalization\n",
    "\n",
    "layer = BatchNormalization()(x)\n",
    "\n",
    "update_ops = []\n",
    "for old_value, new_value in layer.updates:\n",
    "    update_ops.append(tf.assign(old_value, new_value))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense\n",
    "\n",
    "layer = Dense(32)(x)  # instantiate and call a layer\n",
    "print layer.trainable_weights  # list of TensorFlow Variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is our initial Keras model\n",
    "model = Sequential()\n",
    "model.add(Dense(32, activation='relu', input_dim=784))\n",
    "model.add(Dense(10, activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import InputLayer\n",
    "\n",
    "# this is our modified Keras model\n",
    "model = Sequential()\n",
    "model.add(InputLayer(input_tensor=custom_input_tensor,\n",
    "                     input_shape=(None, 784)))\n",
    "\n",
    "# build the rest of the model as before\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(10, activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_tensor = model.output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(32, activation='relu', input_dim=784))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "# this works! \n",
    "x = tf.placeholder(tf.float32, shape=(None, 784))\n",
    "y = model(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('/gpu:0'):\n",
    "    x = tf.placeholder(tf.float32, shape=(None, 20, 64))\n",
    "    y = LSTM(32)(x)  # all ops in the LSTM layer will live on GPU:0\n",
    "\n",
    "with tf.device('/gpu:1'):\n",
    "    x = tf.placeholder(tf.float32, shape=(None, 20, 64))\n",
    "    y = LSTM(32)(x)  # all ops in the LSTM layer will live on GPU:1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('/cpu:0'):\n",
    "    x = tf.placeholder(tf.float32, shape=(None, 784))\n",
    "\n",
    "    # shared model living on CPU:0\n",
    "    # it won't actually be run during training; it acts as an op template\n",
    "    # and as a repository for shared variables\n",
    "    model = Sequential()\n",
    "    model.add(Dense(32, activation='relu', input_dim=784))\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "# replica 0\n",
    "with tf.device('/gpu:0'):\n",
    "    output_0 = model(x)  # all ops in the replica will live on GPU:0\n",
    "\n",
    "# replica 1\n",
    "with tf.device('/gpu:1'):\n",
    "    output_1 = model(x)  # all ops in the replica will live on GPU:1\n",
    "\n",
    "# merge outputs on CPU\n",
    "with tf.device('/cpu:0'):\n",
    "    preds = 0.5 * (output_0 + output_1)\n",
    "\n",
    "# we only run the `preds` tensor, so that only the two\n",
    "# replicas on GPU get run (plus the merge op on CPU)\n",
    "output_value = sess.run([preds], feed_dict={x: data})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "server = tf.train.Server.create_local_server()\n",
    "sess = tf.Session(server.target)\n",
    "\n",
    "from keras import backend as K\n",
    "K.set_session(sess)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "K.set_learning_phase(0)  # all new operations will be in test mode from now on\n",
    "\n",
    "# serialize the model and get its weights, for quick re-building\n",
    "config = previous_model.get_config()\n",
    "weights = previous_model.get_weights()\n",
    "\n",
    "# re-build a model where the learning phase is now hard-coded to 0\n",
    "from keras.models import model_from_config\n",
    "new_model = model_from_config(config)\n",
    "new_model.set_weights(weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow_serving.session_bundle import exporter\n",
    "\n",
    "export_path = ... # where to save the exported graph\n",
    "export_version = ... # version number (integer)\n",
    "\n",
    "saver = tf.train.Saver(sharded=True)\n",
    "model_exporter = exporter.Exporter(saver)\n",
    "signature = exporter.classification_signature(input_tensor=model.input,\n",
    "                                              scores_tensor=model.output)\n",
    "model_exporter.init(sess.graph.as_graph_def(),\n",
    "                    default_graph_signature=signature)\n",
    "model_exporter.export(export_path, tf.constant(export_version), sess)\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
