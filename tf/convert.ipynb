{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to Convert HTML to .ipynb\n",
    "This is the code example used for the blog post [https://www.marsja.se/converting-html-to-a-jupyter-notebook/](https://www.marsja.se/converting-html-to-a-jupyter-notebook/) in which we learn how to convert code chunks from a webpage to a Jupyter notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "import urllib\n",
    "\n",
    "url = 'https://blog.keras.io/keras-as-a-simplified-interface-to-tensorflow-tutorial.html'\n",
    "\n",
    "headers = {'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.11'\\\n",
    "           '(KHTML, like Gecko) Chrome/23.0.1271.64 Safari/537.11',\n",
    "       'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',\n",
    "       'Accept-Charset': 'ISO-8859-1,utf-8;q=0.7,*;q=0.3',\n",
    "       'Accept-Encoding': 'none',\n",
    "       'Accept-Language': 'en-US,en;q=0.8',\n",
    "       'Connection': 'keep-alive'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "req = urllib.request.Request(url, headers=headers)\n",
    "page = urllib.request.urlopen(req)\n",
    "text = page.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(text, 'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_nb = {'nbformat': 4, 'nbformat_minor': 2, \n",
    "              'cells': [], 'metadata': \n",
    "             {\"kernelspec\": \n",
    "              {\"display_name\": \"Python 3\", \n",
    "               \"language\": \"python\", \"name\": \"python3\"\n",
    "  }}}\n",
    "\n",
    "def get_data(soup, content_class):\n",
    "    for div in soup.find_all('div', \n",
    "                             attrs={'class': content_class}):\n",
    "        \n",
    "        code_chunks = div.find_all('div', \n",
    "                             attrs={'class': 'highlight'})\n",
    "        \n",
    "        for chunk in code_chunks:\n",
    "            cell_text = ' '\n",
    "            cell = {}\n",
    "            cell['metadata'] = {}\n",
    "            cell['outputs'] = []\n",
    "            cell['source'] = [chunk.get_text()]\n",
    "            cell['execution_count'] = None\n",
    "            cell['cell_type'] = 'code'\n",
    "            create_nb['cells'].append(cell)\n",
    "\n",
    "get_data(soup, 'entry-content')\n",
    "\n",
    "with open('keras_tensorflow.ipynb', 'w') as jynotebook:\n",
    "    jynotebook.write(json.dumps(create_nb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cells': [{'cell_type': 'code',\n",
       "   'execution_count': None,\n",
       "   'metadata': {},\n",
       "   'outputs': [],\n",
       "   'source': ['import tensorflow as tf\\nsess = tf.Session()\\n\\nfrom keras import backend as K\\nK.set_session(sess)\\n']},\n",
       "  {'cell_type': 'code',\n",
       "   'execution_count': None,\n",
       "   'metadata': {},\n",
       "   'outputs': [],\n",
       "   'source': ['# this placeholder will contain our input digits, as flat vectors\\nimg = tf.placeholder(tf.float32, shape=(None, 784))\\n']},\n",
       "  {'cell_type': 'code',\n",
       "   'execution_count': None,\n",
       "   'metadata': {},\n",
       "   'outputs': [],\n",
       "   'source': [\"from keras.layers import Dense\\n\\n# Keras layers can be called on TensorFlow tensors:\\nx = Dense(128, activation='relu')(img)  # fully-connected layer with 128 units and ReLU activation\\nx = Dense(128, activation='relu')(x)\\npreds = Dense(10, activation='softmax')(x)  # output layer with 10 units and a softmax activation\\n\"]},\n",
       "  {'cell_type': 'code',\n",
       "   'execution_count': None,\n",
       "   'metadata': {},\n",
       "   'outputs': [],\n",
       "   'source': ['labels = tf.placeholder(tf.float32, shape=(None, 10))\\n\\nfrom keras.objectives import categorical_crossentropy\\nloss = tf.reduce_mean(categorical_crossentropy(labels, preds))\\n']},\n",
       "  {'cell_type': 'code',\n",
       "   'execution_count': None,\n",
       "   'metadata': {},\n",
       "   'outputs': [],\n",
       "   'source': [\"from tensorflow.examples.tutorials.mnist import input_data\\nmnist_data = input_data.read_data_sets('MNIST_data', one_hot=True)\\n\\ntrain_step = tf.train.GradientDescentOptimizer(0.5).minimize(loss)\\n\\n# Initialize all variables\\ninit_op = tf.global_variables_initializer()\\nsess.run(init_op)\\n\\n# Run training loop\\nwith sess.as_default():\\n    for i in range(100):\\n        batch = mnist_data.train.next_batch(50)\\n        train_step.run(feed_dict={img: batch[0],\\n                                  labels: batch[1]})\\n\"]},\n",
       "  {'cell_type': 'code',\n",
       "   'execution_count': None,\n",
       "   'metadata': {},\n",
       "   'outputs': [],\n",
       "   'source': ['from keras.metrics import categorical_accuracy as accuracy\\n\\nacc_value = accuracy(labels, preds)\\nwith sess.as_default():\\n    print acc_value.eval(feed_dict={img: mnist_data.test.images,\\n                                    labels: mnist_data.test.labels})\\n']},\n",
       "  {'cell_type': 'code',\n",
       "   'execution_count': None,\n",
       "   'metadata': {},\n",
       "   'outputs': [],\n",
       "   'source': ['from keras import backend as K\\nprint K.learning_phase()\\n']},\n",
       "  {'cell_type': 'code',\n",
       "   'execution_count': None,\n",
       "   'metadata': {},\n",
       "   'outputs': [],\n",
       "   'source': ['# train mode\\ntrain_step.run(feed_dict={x: batch[0], labels: batch[1], K.learning_phase(): 1})\\n']},\n",
       "  {'cell_type': 'code',\n",
       "   'execution_count': None,\n",
       "   'metadata': {},\n",
       "   'outputs': [],\n",
       "   'source': [\"from keras.layers import Dropout\\nfrom keras import backend as K\\n\\nimg = tf.placeholder(tf.float32, shape=(None, 784))\\nlabels = tf.placeholder(tf.float32, shape=(None, 10))\\n\\nx = Dense(128, activation='relu')(img)\\nx = Dropout(0.5)(x)\\nx = Dense(128, activation='relu')(x)\\nx = Dropout(0.5)(x)\\npreds = Dense(10, activation='softmax')(x)\\n\\nloss = tf.reduce_mean(categorical_crossentropy(labels, preds))\\n\\ntrain_step = tf.train.GradientDescentOptimizer(0.5).minimize(loss)\\nwith sess.as_default():\\n    for i in range(100):\\n        batch = mnist_data.train.next_batch(50)\\n        train_step.run(feed_dict={img: batch[0],\\n                                  labels: batch[1],\\n                                  K.learning_phase(): 1})\\n\\nacc_value = accuracy(labels, preds)\\nwith sess.as_default():\\n    print acc_value.eval(feed_dict={img: mnist_data.test.images,\\n                                    labels: mnist_data.test.labels,\\n                                    K.learning_phase(): 0})\\n\"]},\n",
       "  {'cell_type': 'code',\n",
       "   'execution_count': None,\n",
       "   'metadata': {},\n",
       "   'outputs': [],\n",
       "   'source': [\"x = tf.placeholder(tf.float32, shape=(None, 20, 64))\\nwith tf.name_scope('block1'):\\n    y = LSTM(32, name='mylstm')(x)\\n\"]},\n",
       "  {'cell_type': 'code',\n",
       "   'execution_count': None,\n",
       "   'metadata': {},\n",
       "   'outputs': [],\n",
       "   'source': [\"with tf.device('/gpu:0'):\\n    x = tf.placeholder(tf.float32, shape=(None, 20, 64))\\n    y = LSTM(32)(x)  # all ops / variables in the LSTM layer will live on GPU:0\\n\"]},\n",
       "  {'cell_type': 'code',\n",
       "   'execution_count': None,\n",
       "   'metadata': {},\n",
       "   'outputs': [],\n",
       "   'source': ['from keras.layers import LSTM\\nimport tensorflow as tf\\n\\nmy_graph = tf.Graph()\\nwith my_graph.as_default():\\n    x = tf.placeholder(tf.float32, shape=(None, 20, 64))\\n    y = LSTM(32)(x)  # all ops / variables in the LSTM layer are created as part of our graph\\n']},\n",
       "  {'cell_type': 'code',\n",
       "   'execution_count': None,\n",
       "   'metadata': {},\n",
       "   'outputs': [],\n",
       "   'source': ['# instantiate a Keras layer\\nlstm = LSTM(32)\\n\\n# instantiate two TF placeholders\\nx = tf.placeholder(tf.float32, shape=(None, 20, 64))\\ny = tf.placeholder(tf.float32, shape=(None, 20, 64))\\n\\n# encode the two tensors with the *same* LSTM weights\\nx_encoded = lstm(x)\\ny_encoded = lstm(y)\\n']},\n",
       "  {'cell_type': 'code',\n",
       "   'execution_count': None,\n",
       "   'metadata': {},\n",
       "   'outputs': [],\n",
       "   'source': ['from keras.layers import BatchNormalization\\n\\nlayer = BatchNormalization()(x)\\n\\nupdate_ops = []\\nfor old_value, new_value in layer.updates:\\n    update_ops.append(tf.assign(old_value, new_value))\\n']},\n",
       "  {'cell_type': 'code',\n",
       "   'execution_count': None,\n",
       "   'metadata': {},\n",
       "   'outputs': [],\n",
       "   'source': ['from keras.layers import Dense\\n\\nlayer = Dense(32)(x)  # instantiate and call a layer\\nprint layer.trainable_weights  # list of TensorFlow Variables\\n']},\n",
       "  {'cell_type': 'code',\n",
       "   'execution_count': None,\n",
       "   'metadata': {},\n",
       "   'outputs': [],\n",
       "   'source': [\"# this is our initial Keras model\\nmodel = Sequential()\\nmodel.add(Dense(32, activation='relu', input_dim=784))\\nmodel.add(Dense(10, activation='softmax'))\\n\"]},\n",
       "  {'cell_type': 'code',\n",
       "   'execution_count': None,\n",
       "   'metadata': {},\n",
       "   'outputs': [],\n",
       "   'source': [\"from keras.layers import InputLayer\\n\\n# this is our modified Keras model\\nmodel = Sequential()\\nmodel.add(InputLayer(input_tensor=custom_input_tensor,\\n                     input_shape=(None, 784)))\\n\\n# build the rest of the model as before\\nmodel.add(Dense(32, activation='relu'))\\nmodel.add(Dense(10, activation='softmax'))\\n\"]},\n",
       "  {'cell_type': 'code',\n",
       "   'execution_count': None,\n",
       "   'metadata': {},\n",
       "   'outputs': [],\n",
       "   'source': ['output_tensor = model.output\\n']},\n",
       "  {'cell_type': 'code',\n",
       "   'execution_count': None,\n",
       "   'metadata': {},\n",
       "   'outputs': [],\n",
       "   'source': [\"from keras.models import Sequential\\n\\nmodel = Sequential()\\nmodel.add(Dense(32, activation='relu', input_dim=784))\\nmodel.add(Dense(10, activation='softmax'))\\n\\n# this works! \\nx = tf.placeholder(tf.float32, shape=(None, 784))\\ny = model(x)\\n\"]},\n",
       "  {'cell_type': 'code',\n",
       "   'execution_count': None,\n",
       "   'metadata': {},\n",
       "   'outputs': [],\n",
       "   'source': [\"with tf.device('/gpu:0'):\\n    x = tf.placeholder(tf.float32, shape=(None, 20, 64))\\n    y = LSTM(32)(x)  # all ops in the LSTM layer will live on GPU:0\\n\\nwith tf.device('/gpu:1'):\\n    x = tf.placeholder(tf.float32, shape=(None, 20, 64))\\n    y = LSTM(32)(x)  # all ops in the LSTM layer will live on GPU:1\\n\"]},\n",
       "  {'cell_type': 'code',\n",
       "   'execution_count': None,\n",
       "   'metadata': {},\n",
       "   'outputs': [],\n",
       "   'source': [\"with tf.device('/cpu:0'):\\n    x = tf.placeholder(tf.float32, shape=(None, 784))\\n\\n    # shared model living on CPU:0\\n    # it won't actually be run during training; it acts as an op template\\n    # and as a repository for shared variables\\n    model = Sequential()\\n    model.add(Dense(32, activation='relu', input_dim=784))\\n    model.add(Dense(10, activation='softmax'))\\n\\n# replica 0\\nwith tf.device('/gpu:0'):\\n    output_0 = model(x)  # all ops in the replica will live on GPU:0\\n\\n# replica 1\\nwith tf.device('/gpu:1'):\\n    output_1 = model(x)  # all ops in the replica will live on GPU:1\\n\\n# merge outputs on CPU\\nwith tf.device('/cpu:0'):\\n    preds = 0.5 * (output_0 + output_1)\\n\\n# we only run the `preds` tensor, so that only the two\\n# replicas on GPU get run (plus the merge op on CPU)\\noutput_value = sess.run([preds], feed_dict={x: data})\\n\"]},\n",
       "  {'cell_type': 'code',\n",
       "   'execution_count': None,\n",
       "   'metadata': {},\n",
       "   'outputs': [],\n",
       "   'source': ['server = tf.train.Server.create_local_server()\\nsess = tf.Session(server.target)\\n\\nfrom keras import backend as K\\nK.set_session(sess)\\n']},\n",
       "  {'cell_type': 'code',\n",
       "   'execution_count': None,\n",
       "   'metadata': {},\n",
       "   'outputs': [],\n",
       "   'source': ['from keras import backend as K\\n\\nK.set_learning_phase(0)  # all new operations will be in test mode from now on\\n\\n# serialize the model and get its weights, for quick re-building\\nconfig = previous_model.get_config()\\nweights = previous_model.get_weights()\\n\\n# re-build a model where the learning phase is now hard-coded to 0\\nfrom keras.models import model_from_config\\nnew_model = model_from_config(config)\\nnew_model.set_weights(weights)\\n']},\n",
       "  {'cell_type': 'code',\n",
       "   'execution_count': None,\n",
       "   'metadata': {},\n",
       "   'outputs': [],\n",
       "   'source': ['from tensorflow_serving.session_bundle import exporter\\n\\nexport_path = ... # where to save the exported graph\\nexport_version = ... # version number (integer)\\n\\nsaver = tf.train.Saver(sharded=True)\\nmodel_exporter = exporter.Exporter(saver)\\nsignature = exporter.classification_signature(input_tensor=model.input,\\n                                              scores_tensor=model.output)\\nmodel_exporter.init(sess.graph.as_graph_def(),\\n                    default_graph_signature=signature)\\nmodel_exporter.export(export_path, tf.constant(export_version), sess)\\n']}],\n",
       " 'metadata': {'kernelspec': {'display_name': 'Python 3',\n",
       "   'language': 'python',\n",
       "   'name': 'python3'}},\n",
       " 'nbformat': 4,\n",
       " 'nbformat_minor': 2}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_nb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
