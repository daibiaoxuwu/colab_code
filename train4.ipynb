{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3wF5wszaj97Y"
   },
   "source": [
    "# 以相似度为训练目标"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nnrWf3PCEzXL"
   },
   "source": [
    "## 生成训练数据，暂存于本地"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 159
    },
    "colab_type": "code",
    "id": "7aFIIQdwvPPM",
    "outputId": "2700a125-8093-4c89-b2d5-72fbbb06192e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into '05wan2'...\n",
      "remote: Enumerating objects: 49963, done.\u001b[K\n",
      "remote: Counting objects: 100% (49963/49963), done.\u001b[K\n",
      "remote: Compressing objects: 100% (9/9), done.\u001b[K\n",
      "remote: Total 49963 (delta 49954), reused 49963 (delta 49954), pack-reused 0\u001b[K\n",
      "Receiving objects: 100% (49963/49963), 12.79 MiB | 4.64 MiB/s, done.\n",
      "Resolving deltas: 100% (49954/49954), done.\n",
      "Checking out files: 100% (49961/49961), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/daibiaoxuwu/05wan1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 124
    },
    "colab_type": "code",
    "id": "fy2cDLkWvrvl",
    "outputId": "edf44e12-5fa7-4000-eab0-d5e699c3c931"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into '05wan2b'...\n",
      "remote: Enumerating objects: 12, done.\u001b[K\n",
      "remote: Counting objects:   8% (1/12)\u001b[K\r",
      "remote: Counting objects:  16% (2/12)\u001b[K\r",
      "remote: Counting objects:  25% (3/12)\u001b[K\r",
      "remote: Counting objects:  33% (4/12)\u001b[K\r",
      "remote: Counting objects:  41% (5/12)\u001b[K\r",
      "remote: Counting objects:  50% (6/12)\u001b[K\r",
      "remote: Counting objects:  58% (7/12)\u001b[K\r",
      "remote: Counting objects:  66% (8/12)\u001b[K\r",
      "remote: Counting objects:  75% (9/12)\u001b[K\r",
      "remote: Counting objects:  83% (10/12)\u001b[K\r",
      "remote: Counting objects:  91% (11/12)\u001b[K\r",
      "remote: Counting objects: 100% (12/12)\u001b[K\r",
      "remote: Counting objects: 100% (12/12), done.\u001b[K\n",
      "remote: Compressing objects:  33% (1/3)\u001b[K\r",
      "remote: Compressing objects:  66% (2/3)\u001b[K\r",
      "remote: Compressing objects: 100% (3/3)\u001b[K\r",
      "remote: Compressing objects: 100% (3/3), done.\u001b[K\n",
      "Unpacking objects:   8% (1/12)   \r",
      "Unpacking objects:  16% (2/12)   \r",
      "Unpacking objects:  25% (3/12)   \r",
      "Unpacking objects:  33% (4/12)   \r",
      "Unpacking objects:  41% (5/12)   \r",
      "Unpacking objects:  50% (6/12)   \r",
      "Unpacking objects:  58% (7/12)   \r",
      "Unpacking objects:  66% (8/12)   \r",
      "Unpacking objects:  75% (9/12)   \r",
      "Unpacking objects:  83% (10/12)   \r",
      "remote: Total 12 (delta 9), reused 12 (delta 9), pack-reused 0\u001b[K\n",
      "Unpacking objects:  91% (11/12)   \r",
      "Unpacking objects: 100% (12/12)   \r",
      "Unpacking objects: 100% (12/12), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/daibiaoxuwu/05wan1label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "gtgz-INDwsA2",
    "outputId": "c7426626-96c1-448b-8d9e-f8f8011c6c00"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49961 49961\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "path1 = '05wan2'\n",
    "path2 = '05wan2b'\n",
    "\n",
    "clocks = dict()\n",
    "x_train0 = []\n",
    "y_train0 = []\n",
    "for filename in os.listdir(path2):\n",
    "    if 'git' in filename: continue\n",
    "    #print(path1)\n",
    "    #ftimestr,number = path1.split('_')\n",
    "    clocks[int(filename.split('_')[0])]=int(filename.split('_')[1][:-4])\n",
    "    #clocks[int(ftimestr)]=int(number)\n",
    "keys = clocks.keys()\n",
    "for filename in os.listdir(path1):\n",
    "    if 'git' in filename: continue\n",
    "    ftime = int(filename.split('_')[0])\n",
    "    value = max(filter(lambda t:t<ftime,keys))\n",
    "    x_train0.append(cv2.imread(os.path.join(path1,filename), cv2.IMREAD_GRAYSCALE)[:,:,np.newaxis]/255.0)\n",
    "    y_train0.append(clocks[value])\n",
    "    \n",
    "print(len(x_train0),len(y_train0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 303
    },
    "colab_type": "code",
    "id": "d0agG8K9wD3x",
    "outputId": "82a4940f-c54a-4cf0-ef76-20760e7dc720"
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.countplot(y_train0)\n",
    "print(y_train0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-lmz0keARk85"
   },
   "source": [
    "# 转为onehot，分离test和train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7imN2NoQwcBv"
   },
   "outputs": [],
   "source": [
    "from keras.utils.np_utils import to_categorical\n",
    "y_train0 = to_categorical(y_train0, num_classes = 10)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(x_train0, y_train0, test_size = 0.1, random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "8QGa2e83ygoi",
    "outputId": "7b81f99a-6f64-4980-aaee-dcea01e0ce15"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 20, 1) (20, 20, 1) (10,) (10,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train[0].shape, X_val[0].shape, Y_train[0].shape, Y_val[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VBl_86rWRk9F"
   },
   "source": [
    "# 装载Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0trJmd6DjqBZ"
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "# 安装 TensorFlow\n",
    "try:\n",
    "  # Colab only\n",
    "  %tensorflow_version 1.x\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8JqmdPzmRk9Q"
   },
   "source": [
    "# 输入数据生成器"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BPZ68wASog_I"
   },
   "source": [
    "# 构建模型，优化器和损失函数："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "h3IKyzTCDNGo"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\n",
    "from keras.optimizers import RMSprop\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n",
    "                 activation ='relu', input_shape = (20,20,1)))\n",
    "model.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n",
    "                 activation ='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "\n",
    "model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n",
    "                 activation ='relu'))\n",
    "model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n",
    "                 activation ='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation = \"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation = \"softmax\"))\n",
    "\n",
    "optimizer = RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0)\n",
    "model.compile(optimizer = optimizer , loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', \n",
    "                                            patience=3, \n",
    "                                            verbose=1, \n",
    "                                            factor=0.5, \n",
    "                                            min_lr=0.00001)\n",
    "epochs = 30 # Turn epochs to 30 to get 0.9967 accuracy\n",
    "batch_size = 86\n",
    "\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=False,  # apply ZCA whitening\n",
    "        rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        zoom_range = 0.1, # Randomly zoom image \n",
    "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "        horizontal_flip=False,  # randomly flip images\n",
    "        vertical_flip=False)  # randomly flip images\n",
    "\n",
    "\n",
    "datagen.fit(X_train)\n",
    "X_train2=np.array(X_train)\n",
    "X_val2=np.array(X_val)\n",
    "history = model.fit_generator(datagen.flow(X_train2,Y_train, batch_size=batch_size),\n",
    "                              epochs = epochs, validation_data = (X_val2,Y_val),\n",
    "                              verbose = 2, steps_per_epoch=X_train2.shape[0] // batch_size\n",
    "                              , callbacks=[learning_rate_reduction])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ix4mEL65on-w"
   },
   "source": [
    "# 训练并验证模型："
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "anaconda-cloud": {},
  "colab": {
   "collapsed_sections": [],
   "name": "trian2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
